{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import time\n",
        "\n",
        "# Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transformation des données\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Chargement MNIST\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)\n",
        "\n",
        "# Architecture CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64*7*7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.relu(self.conv1(x)))\n",
        "        x = self.pool(torch.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64*7*7)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Entraînement et évaluation\n",
        "def train_cnn(epochs=10):\n",
        "    model = CNN().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    train_times = []\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        train_time = time.time() - start_time\n",
        "        train_times.append(train_time)\n",
        "\n",
        "        # Évaluation\n",
        "        model.eval()\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images.to(device))\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_targets.extend(labels.cpu().numpy())\n",
        "\n",
        "        accuracy = accuracy_score(all_targets, all_preds)\n",
        "        f1 = f1_score(all_targets, all_preds, average='macro')\n",
        "        print(f'Epoch {epoch+1}: Train Loss: {total_loss/len(train_loader):.4f}, Accuracy: {accuracy:.4f}, F1: {f1:.4f}, Time: {train_time:.2f}s')\n",
        "\n",
        "    avg_time = sum(train_times)/len(train_times)\n",
        "    print(f'Average epoch time: {avg_time:.2f}s')\n",
        "    return model\n",
        "\n",
        "# Exécution\n",
        "cnn_model = train_cnn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fa-L3aUKWXl8",
        "outputId": "a867a716-774c-484a-d469-44350c531452"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Train Loss: 0.2017, Accuracy: 0.9860, F1: 0.9859, Time: 16.70s\n",
            "Epoch 2: Train Loss: 0.0790, Accuracy: 0.9885, F1: 0.9885, Time: 17.43s\n",
            "Epoch 3: Train Loss: 0.0564, Accuracy: 0.9904, F1: 0.9903, Time: 17.14s\n",
            "Epoch 4: Train Loss: 0.0467, Accuracy: 0.9917, F1: 0.9916, Time: 15.27s\n",
            "Epoch 5: Train Loss: 0.0400, Accuracy: 0.9917, F1: 0.9916, Time: 15.34s\n",
            "Epoch 6: Train Loss: 0.0345, Accuracy: 0.9927, F1: 0.9926, Time: 15.81s\n",
            "Epoch 7: Train Loss: 0.0292, Accuracy: 0.9926, F1: 0.9925, Time: 15.35s\n",
            "Epoch 8: Train Loss: 0.0285, Accuracy: 0.9923, F1: 0.9922, Time: 15.55s\n",
            "Epoch 9: Train Loss: 0.0236, Accuracy: 0.9931, F1: 0.9930, Time: 15.25s\n",
            "Epoch 10: Train Loss: 0.0216, Accuracy: 0.9920, F1: 0.9919, Time: 15.92s\n",
            "Average epoch time: 15.98s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Architecture MiniFasterRCNN\n",
        "class MiniFasterRCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "            nn.Conv2d(16, 32, 3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(32*7*7, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.classifier(x)\n",
        "\n",
        "# Entraînement spécifique RCNN\n",
        "def train_frcnn(epochs=5):\n",
        "    model = MiniFasterRCNN().to(device)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # Adaptation des données pour RCNN\n",
        "    def collate_fn(batch):\n",
        "        images = torch.stack([item[0] for item in batch])\n",
        "        targets = [{'labels': torch.tensor(item[1], dtype=torch.int64)} for item in batch]\n",
        "        return images, targets\n",
        "\n",
        "    frcnn_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "\n",
        "        for images, targets in frcnn_loader:\n",
        "            images = images.to(device)\n",
        "            targets = [{k: v.to(device) for k,v in t.items()} for t in targets]\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, torch.stack([t['labels'] for t in targets]))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Évaluation simplifiée\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                outputs = model(images.to(device))\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                correct += (preds == labels.to(device)).sum().item()\n",
        "\n",
        "        acc = correct / len(test_dataset)\n",
        "        print(f'Epoch {epoch+1}: Loss {total_loss/len(frcnn_loader):.4f}, Acc: {acc:.4f}, Time: {time.time()-start_time:.2f}s')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Exécution\n",
        "frcnn_model = train_frcnn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U7cCCln0Waje",
        "outputId": "ccd796dd-3874-4ce2-9bf6-19ffeaa4e744"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Loss 0.1319, Acc: 0.9840, Time: 20.90s\n",
            "Epoch 2: Loss 0.0435, Acc: 0.9876, Time: 21.12s\n",
            "Epoch 3: Loss 0.0312, Acc: 0.9885, Time: 20.09s\n",
            "Epoch 4: Loss 0.0235, Acc: 0.9845, Time: 20.86s\n",
            "Epoch 5: Loss 0.0187, Acc: 0.9916, Time: 20.85s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compare_models(cnn_model, frcnn_model):\n",
        "    # Fonction d'évaluation commune\n",
        "    def evaluate(model, loader):\n",
        "        model.eval()\n",
        "        all_preds, all_targets = [], []\n",
        "        with torch.no_grad():\n",
        "            for images, labels in loader:\n",
        "                outputs = model(images.to(device))\n",
        "                preds = outputs.argmax(dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_targets.extend(labels.cpu().numpy())\n",
        "        return {\n",
        "            'accuracy': accuracy_score(all_targets, all_preds),\n",
        "            'f1': f1_score(all_targets, all_preds, average='macro')\n",
        "        }\n",
        "\n",
        "    # Mesure du temps d'inférence\n",
        "    def benchmark(model, loader):\n",
        "        model.eval()\n",
        "        start = time.time()\n",
        "        with torch.no_grad():\n",
        "            for images, _ in loader:\n",
        "                _ = model(images.to(device))\n",
        "        return (time.time() - start) / len(loader.dataset)\n",
        "\n",
        "    # Évaluation\n",
        "    cnn_metrics = evaluate(cnn_model, test_loader)\n",
        "    frcnn_metrics = evaluate(frcnn_model, test_loader)\n",
        "\n",
        "    # Benchmark\n",
        "    cnn_time = benchmark(cnn_model, test_loader)\n",
        "    frcnn_time = benchmark(frcnn_model, test_loader)\n",
        "\n",
        "    # Affichage\n",
        "    print(\"\\nComparaison détaillée:\")\n",
        "    print(f\"{'Metric':<15}{'CNN':<15}{'MiniFasterRCNN':<15}\")\n",
        "    print(f\"{'Accuracy':<15}{cnn_metrics['accuracy']:<15.4f}{frcnn_metrics['accuracy']:<15.4f}\")\n",
        "    print(f\"{'F1 Score':<15}{cnn_metrics['f1']:<15.4f}{frcnn_metrics['f1']:<15.4f}\")\n",
        "    print(f\"{'Inference Time':<15}{cnn_time:<15.6f}{frcnn_time:<15.6f}\")\n",
        "\n",
        "# Exécution\n",
        "compare_models(cnn_model, frcnn_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAZ9CvYoWfHE",
        "outputId": "fe16ad0d-0348-485a-9ace-82ca2e45a0c0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparaison détaillée:\n",
            "Metric         CNN            MiniFasterRCNN \n",
            "Accuracy       0.9920         0.9916         \n",
            "F1 Score       0.9919         0.9915         \n",
            "Inference Time 0.000192       0.000196       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modifiez votre fonction fine_tune_model comme suit :\n",
        "def fine_tune_model(model_name, num_epochs=3):\n",
        "    try:\n",
        "        # Chargement avec la nouvelle syntaxe (PyTorch >= 0.13)\n",
        "        if model_name == 'vgg16':\n",
        "            model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1)\n",
        "            model.classifier[6] = nn.Linear(4096, 10)\n",
        "        elif model_name == 'alexnet':\n",
        "            model = models.alexnet(weights=models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "            model.classifier[6] = nn.Linear(4096, 10)\n",
        "\n",
        "        model = model.to(device)\n",
        "\n",
        "        # Réduire la taille du batch pour économiser de la mémoire\n",
        "        train_loader_p = DataLoader(train_pretrain, batch_size=32, shuffle=True)\n",
        "        test_loader_p = DataLoader(test_pretrain, batch_size=64, shuffle=False)\n",
        "\n",
        "        # Optimiseur plus léger\n",
        "        optimizer = optim.AdamW(model.parameters(), lr=0.0001, weight_decay=0.01)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
        "\n",
        "        print(f\"\\nFine-tuning {model_name} (batch_size=32)...\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            model.train()\n",
        "            running_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            for i, (images, labels) in enumerate(train_loader_p):\n",
        "                # Libération explicite de la mémoire\n",
        "                if i % 100 == 0:\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                optimizer.zero_grad(set_to_none=True)  # Plus efficace pour la mémoire\n",
        "\n",
        "                with torch.cuda.amp.autocast():  # Mixed precision\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                running_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "            scheduler.step()\n",
        "            epoch_acc = correct / total\n",
        "            print(f'Epoch {epoch+1}/{num_epochs} - Loss: {running_loss/len(train_loader_p):.4f} - Acc: {epoch_acc:.4f}')\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Évaluation avec garbage collection\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader_p:\n",
        "                images = images.to(device)\n",
        "                outputs = model(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                correct += (predicted == labels.to(device)).sum().item()\n",
        "                del images, outputs, predicted\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        final_acc = correct / len(test_pretrain)\n",
        "        train_time = time.time() - start_time\n",
        "        print(f'{model_name} - Final Test Accuracy: {final_acc:.4f} - Training Time: {train_time:.2f}s')\n",
        "        return final_acc, train_time\n",
        "\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Erreur avec {model_name}: {str(e)}\")\n",
        "        return 0.0, 0.0\n",
        "\n",
        "# Configuration pour économiser la mémoire\n",
        "torch.backends.cudnn.benchmark = True\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Exécution séquentielle pour économiser la mémoire\n",
        "print(\"Début du fine-tuning...\")\n",
        "vgg_acc, vgg_time = fine_tune_model('vgg16')\n",
        "alex_acc, alex_time = fine_tune_model('alexnet')\n",
        "\n",
        "# Si VGG16 échoue toujours, essayer avec une version plus petite\n",
        "if vgg_acc == 0.0:\n",
        "    print(\"\\nEssai avec VGG11...\")\n",
        "    model = models.vgg11(weights=models.VGG11_Weights.IMAGENET1K_V1)\n",
        "    model.classifier[6] = nn.Linear(4096, 10)\n",
        "    vgg_acc, vgg_time = fine_tune_model('vgg11')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KDUQ_DvjobW",
        "outputId": "18c4223b-8956-495d-a074-941328061e9c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Début du fine-tuning...\n",
            "\n",
            "Fine-tuning vgg16 (batch_size=32)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-16-271e44cfa41e>:40: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():  # Mixed precision\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3 - Loss: 0.0782 - Acc: 0.9775\n",
            "Epoch 2/3 - Loss: 0.0145 - Acc: 0.9960\n",
            "Epoch 3/3 - Loss: 0.0075 - Acc: 0.9981\n",
            "vgg16 - Final Test Accuracy: 0.9963 - Training Time: 1778.17s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:05<00:00, 44.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fine-tuning alexnet (batch_size=32)...\n",
            "Epoch 1/3 - Loss: 0.0820 - Acc: 0.9751\n",
            "Epoch 2/3 - Loss: 0.0178 - Acc: 0.9945\n",
            "Epoch 3/3 - Loss: 0.0108 - Acc: 0.9970\n",
            "alexnet - Final Test Accuracy: 0.9948 - Training Time: 528.87s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import time\n",
        "\n",
        "# Configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Transformation des données\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "# Chargement MNIST\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "class EfficientViT(nn.Module):\n",
        "    def __init__(self, image_size=28, patch_size=7, num_classes=10, dim=48, depth=2, heads=3):\n",
        "        super().__init__()\n",
        "        num_patches = (image_size // patch_size) ** 2\n",
        "        self.patch_size = patch_size\n",
        "\n",
        "        # Patch embedding plus efficace\n",
        "        self.patch_embed = nn.Conv2d(1, dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "        # Token de classe et position embedding\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n",
        "        self.pos_embed = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n",
        "\n",
        "        # Transformer optimisé\n",
        "        self.transformer = nn.TransformerEncoder(\n",
        "            nn.TransformerEncoderLayer(\n",
        "                d_model=dim,\n",
        "                nhead=heads,\n",
        "                dim_feedforward=dim*2,\n",
        "                dropout=0.1,\n",
        "                activation='gelu',\n",
        "                batch_first=True,\n",
        "                norm_first=True\n",
        "            ),\n",
        "            num_layers=depth\n",
        "        )\n",
        "\n",
        "        # Tête de classification\n",
        "        self.head = nn.Sequential(\n",
        "            nn.LayerNorm(dim),\n",
        "            nn.Linear(dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Embedding des patches\n",
        "        x = self.patch_embed(x)  # [B, dim, H', W']\n",
        "        x = x.flatten(2).transpose(1, 2)  # [B, num_patches, dim]\n",
        "\n",
        "        # Ajout du token [CLS]\n",
        "        cls_tokens = self.cls_token.expand(x.size(0), -1, -1)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "\n",
        "        # Ajout position embedding\n",
        "        x += self.pos_embed\n",
        "\n",
        "        # Transformer\n",
        "        x = self.transformer(x)\n",
        "\n",
        "        # Classification\n",
        "        return self.head(x[:, 0])\n",
        "\n",
        "def train_efficient_vit(epochs=5, batch_size=32):\n",
        "    # Initialisation\n",
        "    model = EfficientViT().to(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, epochs)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    # DataLoader\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "    # Entraînement\n",
        "    print(f\"\\nTraining EfficientViT for {epochs} epochs...\")\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "            # Forward + backward\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Métriques\n",
        "            total_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "        scheduler.step()\n",
        "        epoch_acc = correct / len(train_dataset)\n",
        "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss/len(train_loader):.4f} - Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "    # Évaluation\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            outputs = model(images.to(device))\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            correct += (predicted == labels.to(device)).sum().item()\n",
        "\n",
        "    final_acc = correct / len(test_dataset)\n",
        "    train_time = time.time() - start_time\n",
        "    params = sum(p.numel() for p in model.parameters()) / 1e6\n",
        "\n",
        "    print(f\"\\nTraining Complete!\")\n",
        "    print(f\"- Final Accuracy: {final_acc:.4f}\")\n",
        "    print(f\"- Training Time: {train_time:.2f}s\")\n",
        "    print(f\"- Parameters: {params:.2f}M\")\n",
        "\n",
        "    return model, final_acc, train_time\n",
        "\n",
        "# Exécution\n",
        "vit_model, vit_acc, vit_time = train_efficient_vit()\n",
        "\n",
        "# Charger les résultats CNN si nécessaire\n",
        "# cnn_model, cnn_acc, cnn_time = ...\n",
        "\n",
        "# Comparaison\n",
        "print(\"\\nModel Comparison:\")\n",
        "print(f\"{'Model':<15}{'Accuracy':<12}{'Time (s)':<12}{'Params (M)':<12}\")\n",
        "print(f\"{'CNN':<15}{cnn_acc:<12.4f}{cnn_time:<12.2f}{sum(p.numel() for p in cnn_model.parameters())/1e6:<12.2f}\")\n",
        "print(f\"{'EfficientViT':<15}{vit_acc:<12.4f}{vit_time:<12.2f}{sum(p.numel() for p in vit_model.parameters())/1e6:<12.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpIf38DqYfwV",
        "outputId": "5a4b40c2-2535-4974-dfd6-2ee9fc17eea0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training EfficientViT for 5 epochs...\n",
            "Epoch 1/5 - Loss: 0.6906 - Acc: 0.7800\n",
            "Epoch 2/5 - Loss: 0.3133 - Acc: 0.9042\n",
            "Epoch 3/5 - Loss: 0.2506 - Acc: 0.9224\n",
            "Epoch 4/5 - Loss: 0.2192 - Acc: 0.9324\n",
            "Epoch 5/5 - Loss: 0.2041 - Acc: 0.9379\n",
            "\n",
            "Training Complete!\n",
            "- Final Accuracy: 0.9554\n",
            "- Training Time: 133.88s\n",
            "- Parameters: 0.04M\n",
            "\n",
            "Model Comparison:\n",
            "Model          Accuracy    Time (s)    Params (M)  \n",
            "CNN            0.9901      53.24       0.42        \n",
            "EfficientViT   0.9554      133.88      0.04        \n"
          ]
        }
      ]
    }
  ]
}